# Copyright 2023 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
#
# This file has been derived from the https://github.com/huggingface/pytorch-image-models
# repository and modified.
# ============================================================================

"""Weights init functions"""


import math
import warnings

import numpy as np

import mindspore as ms
from mindspore.ops import Erfinv, Mul, Add, clip_by_value

def _no_grad_trunc_normal_(tensor, mean, std, a, b):
    """Trunc normal function"""
    # Cut & paste from PyTorch official master until it's
    # in a few official releases - RW
    # Method based on
    # https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf

    def norm_cdf(x):
        # Computes standard normal cumulative distribution function
        return (1. + math.erf(x / math.sqrt(2.))) / 2.

    if (mean < a - 2 * std) or (mean > b + 2 * std):
        warnings.warn('mean is more than 2 std from [a, b] '
                      'in nn.init.trunc_normal_. '
                      'The distribution of values may be incorrect.',
                      stacklevel=2)


    # Values are generated by using a truncated uniform distribution and
    # then using the inverse CDF for the normal distribution.
    # Get upper and lower cdf values
    l = norm_cdf((a - mean) / std)
    u = norm_cdf((b - mean) / std)

    # Uniformly fill tensor with values from [l, u], then translate to
    # [2l-1, 2u-1].
    shape = tensor.shape
    numpy_tensor = np.random.uniform(2 * l - 1, 2 * u - 1, shape)

    tensor_tmp = ms.Tensor(numpy_tensor, ms.float32)
    tensor.assign_value(tensor_tmp)


    # Use inverse cdf transform for normal distribution to get truncated
    # standard normal
    tensor = Erfinv()(tensor)

    # Transform to proper mean, std
    tensor = Mul()(tensor, std * math.sqrt(2.))
    tensor = Add()(tensor, mean)

    # Clamp to ensure it's in the proper range
    tensor = clip_by_value(tensor, a, b)
    return tensor


def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):
    """
    Fills the input Tensor with values drawn from a truncated
    normal distribution.
    Args:
        tensor: an n-dimensional `torch.Tensor`
        mean: the mean of the normal distribution
        std: the standard deviation of the normal distribution
        a: the minimum cutoff value
        b: the maximum cutoff value
    """
    return _no_grad_trunc_normal_(tensor, mean, std, a, b)
